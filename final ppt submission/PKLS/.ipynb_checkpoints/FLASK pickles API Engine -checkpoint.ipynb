{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "musical-monaco",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# from skl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "import nltk\n",
    "# nltk.download('stopwords')\n",
    "# print('Downloaded Stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "from xgboost import XGBRegressor\n",
    "import xgboost as xgb\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import seaborn as sns\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neighbors  import KNeighborsRegressor \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from spacy.lang.en import English\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "stop_words = STOP_WORDS\n",
    "import string\n",
    "punctuations = string.punctuation\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "\n",
    "\n",
    "\n",
    "# from one daal\n",
    "from daal4py.sklearn.ensemble import RandomForestRegressor as d4prdf\n",
    "from daal4py.sklearn.neighbors  import KNeighborsRegressor as d4pknr \n",
    "from daal4py.sklearn.linear_model import LogisticRegression as d4plr\n",
    "from daal4py.sklearn.model_selection import _daal_train_test_split as d4ptts\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "earlier-champagne",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = English()\n",
    "class predictors(TransformerMixin):\n",
    "    def transform(self, X, **transform_params):\n",
    "        \n",
    "        return [clean_text(text) for text in X]\n",
    "\n",
    "    def fit(self, X, y, **fit_params):\n",
    "        return self\n",
    "\n",
    "    def get_params(self, deep=True):\n",
    "        return {}\n",
    "\n",
    "\n",
    "def clean_text(text):\n",
    "   \n",
    "    return text.strip().lower()\n",
    "\n",
    "\n",
    "def spacy_tokenizer(sentence):\n",
    "    # Creating our token object, which is used to create documents with linguistic annotations.\n",
    "    mytokens = nlp(sentence)\n",
    "\n",
    "    # here the token is converted into lowercase if it is a Pronoun and if it is not a Pronoun then it is lemmatized and lowercased    \n",
    "    mytokens = [ word.lemma_.lower().strip() if word.lemma_ != \"-PRON-\" else word.lower_ for word in mytokens ]\n",
    "\n",
    "    # Removing stop words using stopword from spacy library and punctuations from string library\n",
    "    mytokens = [ word for word in mytokens if word not in stop_words and word not in punctuations ]\n",
    "\n",
    "    # return preprocessed list of tokens\n",
    "    return mytokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "neutral-brand",
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_vector = CountVectorizer(max_features = 100,tokenizer = spacy_tokenizer,ngram_range=(1,2))\n",
    "\n",
    "xgboost = MultiOutputRegressor(XGBRegressor())\n",
    "rand_for = MultiOutputRegressor(RandomForestRegressor(n_estimators=100,max_depth=None,random_state=0))\n",
    "rand_for_d4prfr = MultiOutputRegressor(d4prdf(n_estimators=100,max_depth=None,random_state=0))\n",
    "\n",
    "knnr = MultiOutputRegressor(KNeighborsRegressor())\n",
    "d4pknr = MultiOutputRegressor(d4pknr())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "unsigned-martin",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loding pipelines\n",
    "# sikitlearn  KNeighbors forest\n",
    "# Title\n",
    "skl_pipe_title_knr = Pipeline([(\"cleaner\", predictors()),\n",
    "                 ('vectorizer', bow_vector),\n",
    "                 ('tfidf',TfidfTransformer()),\n",
    "                 ('regressor', knnr)])\n",
    "# Headline\n",
    "skl_pipe_headline_knr = Pipeline([(\"cleaner\", predictors()),\n",
    "                 ('vectorizer', bow_vector),\n",
    "                 ('tfidf',TfidfTransformer()),\n",
    "                 ('regressor', knnr)])\n",
    "\n",
    "# daal4py  KNeighbors forest\n",
    "# Title\n",
    "d4p_pipe_title_knr = Pipeline([(\"cleaner\", predictors()),\n",
    "                 ('vectorizer', bow_vector),\n",
    "                 ('tfidf',TfidfTransformer()),\n",
    "                 ('regressor', d4pknr)])\n",
    "# headline\n",
    "d4p_pipe_headline_knr = Pipeline([(\"cleaner\", predictors()),\n",
    "                 ('vectorizer', bow_vector),\n",
    "                 ('tfidf',TfidfTransformer()),\n",
    "                 ('regressor', d4pknr)])\n",
    "\n",
    "# daal4py Random forest\n",
    "# title\n",
    "skl_pipe_title_rdf = Pipeline([(\"cleaner\", predictors()),\n",
    "                 ('vectorizer', bow_vector),\n",
    "                 ('tfidf',TfidfTransformer()),\n",
    "                 ('regressor', rand_for)])\n",
    "# headline\n",
    "skl_pipe_headline_rdf = Pipeline([(\"cleaner\", predictors()),\n",
    "                 ('vectorizer', bow_vector),\n",
    "                 ('tfidf',TfidfTransformer()),\n",
    "                 ('regressor', rand_for)])\n",
    "\n",
    "\n",
    "# daal4py Random forest\n",
    "# title\n",
    "d4p_pipe_title_rdf = Pipeline([(\"cleaner\", predictors()),\n",
    "                 ('vectorizer', bow_vector),\n",
    "                 ('tfidf',TfidfTransformer()),\n",
    "                 ('regressor', rand_for_d4prfr)])\n",
    "# headline\n",
    "d4p_pipe_headline_rdf = Pipeline([(\"cleaner\", predictors()),\n",
    "                 ('vectorizer', bow_vector),\n",
    "                 ('tfidf',TfidfTransformer()),\n",
    "                 ('regressor', rand_for_d4prfr)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "complex-practice",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "new_data = [\"In break, top EU official suggests Israel-Palestine 'confederation'\"] \n",
    "\n",
    "# Load the pipeline from the pickle file\n",
    "with open('pipe_title_d4pknr.pkl', 'rb') as f:\n",
    "    loaded_pipeline_knr = pickle.load(f)\n",
    "\n",
    "# Use the loaded model for prediction\n",
    "predictions_knr = loaded_pipeline_knr.predict(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "annual-adelaide",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_knr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "attractive-recipe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-c618834c888a>:2: DeprecationWarning: Please use `csr_matrix` from the `scipy.sparse` namespace, the `scipy.sparse.csr` namespace is deprecated.\n",
      "  loaded_model_d4p_rdf = pickle.load(f)\n",
      "c:\\users\\hp\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\base.py:329: UserWarning: Trying to unpickle estimator DecisionTreeRegressor from version 0.23.2 when using version 1.1.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "with open('pipe_title_d4prdf.pkl', 'rb') as f:\n",
    "    loaded_model_d4p_rdf = pickle.load(f)\n",
    "\n",
    "# Use the loaded model for prediction\n",
    "\n",
    "predictions_rdf = loaded_model_d4p_rdf.predict(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "otherwise-store",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.03469011]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_rdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "whole-holiday",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
      " * Running on http://127.0.0.1:5000\n",
      "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n",
      "INFO:werkzeug:127.0.0.1 - - [01/Jun/2023 10:37:01] \"OPTIONS /process HTTP/1.1\" 200 -\n",
      "<ipython-input-9-d65f37d7c384>:14: DeprecationWarning: Please use `csr_matrix` from the `scipy.sparse` namespace, the `scipy.sparse.csr` namespace is deprecated.\n",
      "  loaded_pipeline_knr_opp = pickle.load(f)\n",
      "INFO:werkzeug:127.0.0.1 - - [01/Jun/2023 10:37:01] \"POST /process HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pass 2\n",
      "Pass 3\n",
      "[[-0.07454773]]\n",
      "Pass 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:werkzeug:127.0.0.1 - - [01/Jun/2023 10:37:02] \"POST /process HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pass 2\n",
      "Pass 3\n",
      "[[-0.07454773]]\n",
      "Pass 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:werkzeug:127.0.0.1 - - [01/Jun/2023 10:37:06] \"OPTIONS /process HTTP/1.1\" 200 -\n",
      "INFO:werkzeug:127.0.0.1 - - [01/Jun/2023 10:37:06] \"POST /process HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pass 2\n",
      "Pass 3\n",
      "[[-0.07454773]]\n",
      "Pass 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:werkzeug:127.0.0.1 - - [01/Jun/2023 10:37:11] \"\u001b[31m\u001b[1mPOST /process HTTP/1.1\u001b[0m\" 415 -\n",
      "INFO:werkzeug:127.0.0.1 - - [01/Jun/2023 10:37:42] \"OPTIONS /process HTTP/1.1\" 200 -\n",
      "INFO:werkzeug:127.0.0.1 - - [01/Jun/2023 10:37:42] \"POST /process HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pass 2\n",
      "Pass 3\n",
      "[[-0.07454773]]\n",
      "Pass 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:werkzeug:127.0.0.1 - - [01/Jun/2023 10:37:55] \"OPTIONS /process HTTP/1.1\" 200 -\n",
      "INFO:werkzeug:127.0.0.1 - - [01/Jun/2023 10:37:55] \"POST /process HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pass 2\n",
      "Pass 3\n",
      "[[-0.07454773]]\n",
      "Pass 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:werkzeug:127.0.0.1 - - [01/Jun/2023 10:38:08] \"OPTIONS /process HTTP/1.1\" 200 -\n",
      "INFO:werkzeug:127.0.0.1 - - [01/Jun/2023 10:38:08] \"POST /process HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pass 2\n",
      "Pass 3\n",
      "[[-0.07454773]]\n",
      "Pass 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:werkzeug:127.0.0.1 - - [01/Jun/2023 10:39:43] \"OPTIONS /process HTTP/1.1\" 200 -\n",
      "INFO:werkzeug:127.0.0.1 - - [01/Jun/2023 10:39:43] \"POST /process HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pass 2\n",
      "Pass 3\n",
      "[[-0.07454773]]\n",
      "Pass 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:werkzeug:127.0.0.1 - - [01/Jun/2023 10:39:44] \"POST /process HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pass 2\n",
      "Pass 3\n",
      "[[-0.07454773]]\n",
      "Pass 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:werkzeug:127.0.0.1 - - [01/Jun/2023 10:39:44] \"POST /process HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pass 2\n",
      "Pass 3\n",
      "[[-0.07454773]]\n",
      "Pass 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:werkzeug:127.0.0.1 - - [01/Jun/2023 10:39:46] \"POST /process HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pass 2\n",
      "Pass 3\n",
      "[[-0.07454773]]\n",
      "Pass 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:werkzeug:127.0.0.1 - - [01/Jun/2023 10:42:04] \"OPTIONS /process HTTP/1.1\" 200 -\n",
      "INFO:werkzeug:127.0.0.1 - - [01/Jun/2023 10:42:04] \"POST /process HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pass 2\n",
      "Pass 3\n",
      "[[-0.07454773]]\n",
      "Pass 4\n"
     ]
    }
   ],
   "source": [
    "# from flask import Flask, request\n",
    "# from flask_cors import CORS\n",
    "# app = Flask(__name__)\n",
    "# CORS(app)\n",
    "# @app.route('/process', methods=['POST'])\n",
    "# def process_post_request():\n",
    "#     data = request.get_json()  # Get the JSON data from the request\n",
    "#     data_query=data['query']\n",
    "#     print(\"Pass 2\")\n",
    "#     # Process the data as needed\n",
    "#     # ...\n",
    "#     # Load the pipeline from the pickle file\n",
    "#     with open('pipe_title_d4pknr.pkl', 'rb') as f:\n",
    "#         loaded_pipeline_knr_opp = pickle.load(f)\n",
    "#     print(\"Pass 3\")\n",
    "\n",
    "#     # Use the loaded model for prediction\n",
    "#     predictions_st = loaded_pipeline_knr_opp.predict([data_query])\n",
    "#     print(predictions_st)\n",
    "#     print(\"Pass 4\")\n",
    "    \n",
    "    \n",
    "    \n",
    "#     # Return a response\n",
    "#     response = {'query': data['query'],'SentimentTitle':predictions_st[0][0]}\n",
    "#     return response\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     app.run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stock-continent",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
